"""
Reasoning Engine - AURA's Thinking Brain
Makes autonomous decisions, plans actions, learns from context
NOT hardcoded - uses LLM reasoning to decide WHAT to do
"""

import logging
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

from ..tools.tool_executor import ToolExecutor

logger = logging.getLogger(__name__)


@dataclass
class Task:
    """A task that needs to be accomplished"""
    id: str
    description: str
    context: Dict[str, Any]
    priority: float  # 0.0 to 1.0
    created_at: datetime
    deadline: Optional[datetime] = None
    steps: List[Dict] = None
    status: str = "pending"  # pending, in_progress, completed, failed


@dataclass
class ActionPlan:
    """Plan of actions generated by reasoning"""
    goal: str
    reasoning: str
    actions: List[Dict]
    fallback: Optional[str] = None


class ReasoningEngine:
    """
    Core reasoning system - like OpenClaw's agent loop
    Analyzes situation, makes decisions, plans actions
    """
    
    def __init__(self, llm_server, memory_system, tool_executor: ToolExecutor):
        self.llm = llm_server
        self.memory = memory_system
        self.tools = tool_executor
        self.active_tasks: Dict[str, Task] = {}
        
    async def reason_about_event(self, event: Dict) -> ActionPlan:
        """
        Main reasoning entry point
        Given an event (call, notification, user request), decide what to do
        """
        event_type = event.get('type', 'unknown')
        event_data = event.get('data', {})
        
        logger.info(f"ðŸ§  Reasoning about {event_type} event")
        
        # Gather context
        context = await self._gather_context(event)
        
        # Build reasoning prompt
        prompt = self._build_reasoning_prompt(event_type, event_data, context)
        
        # Get LLM reasoning
        llm_response = self.llm.generate(prompt=prompt, max_tokens=1024, temperature=0.7)
        
        # Parse response into action plan
        plan = self._parse_reasoning_response(llm_response, event)
        
        logger.info(f"ðŸ“ Generated plan: {plan.goal}")
        logger.info(f"ðŸ” Reasoning: {plan.reasoning[:100]}...")
        
        return plan
    
    async def _gather_context(self, event: Dict) -> str:
        """Gather relevant context for reasoning"""
        context_parts = []
        
        # Get recent memory
        recent = self.memory.get_context_for_llm(max_items=5)
        if recent:
            context_parts.append("Recent context:")
            context_parts.append(recent)
        
        # Event-specific context
        if event['type'] == 'call':
            caller = event['data'].get('name', event['data'].get('number', 'Unknown'))
            # Search for previous interactions
            related = self.memory.recall(caller, limit=3)
            if related:
                context_parts.append(f"\nPrevious with {caller}:")
                for item in related:
                    context_parts.append(f"- {item['content']}")
        
        return "\n".join(context_parts)
    
    def _build_reasoning_prompt(self, event_type: str, event_data: Dict, context: str) -> str:
        """Build prompt for LLM reasoning"""
        
        # Get available tools
        tools_desc = self.tools.registry.get_tool_descriptions()
        
        prompt = f"""You are AURA, an intelligent AI assistant running locally on an Android phone. You have full access to the device and can perform real actions.

EVENT TYPE: {event_type}
EVENT DATA: {json.dumps(event_data, indent=2)}

{context}

{tools_desc}

SECURITY CONSTRAINTS (never violate these):
- Never share passwords or sensitive data
- Never make financial transactions
- Never install unknown apps
- Always ask user permission for irreversible actions (sending messages, making calls)
- Respect privacy - don't read unrelated messages or data

TASK: Analyze this event and create an action plan.

You MUST respond in this JSON format:
```json
{{
  "goal": "One sentence describing what needs to be done",
  "reasoning": "Your step-by-step thinking about what to do and why",
  "actions": [
    {{
      "tool": "tool_name",
      "params": {{"param1": "value1", "param2": "value2"}},
      "reasoning": "Why this specific action"
    }}
  ],
  "ask_user_first": true/false,
  "user_message": "What to tell the user (if ask_user_first is true)"
}}
```

If the action requires user confirmation (sending messages, making calls, sharing data), set "ask_user_first" to true and provide a "user_message" explaining what you want to do and why.

Think carefully about each step. Consider:
1. What is the user likely trying to accomplish?
2. What information do I need?
3. What tools should I use?
4. Are there any security concerns?
5. Should I ask the user first?

Provide your response:"""
        
        return prompt
    
    def _parse_reasoning_response(self, response: str, event: Dict) -> ActionPlan:
        """Parse LLM reasoning into action plan"""
        
        # Extract JSON from response
        import re
        json_match = re.search(r'```(?:json)?\s*({[\s\S]*?})\s*```', response)
        
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                
                return ActionPlan(
                    goal=data.get('goal', 'Handle event'),
                    reasoning=data.get('reasoning', 'No reasoning provided'),
                    actions=data.get('actions', []),
                    fallback=data.get('user_message') if data.get('ask_user_first') else None
                )
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse reasoning JSON: {e}")
        
        # Fallback: simple plan
        return ActionPlan(
            goal=f"Handle {event.get('type', 'unknown')} event",
            reasoning=response[:200],
            actions=[],
            fallback="I received the event but couldn't determine the best action."
        )
    
    async def execute_plan(self, plan: ActionPlan, require_confirmation: bool = True) -> Dict:
        """
        Execute an action plan
        If require_confirmation is True, will ask user before sensitive actions
        """
        results = {
            "plan": plan.goal,
            "executed": [],
            "failed": [],
            "asked_user": False
        }
        
        # Check if we need user confirmation
        if plan.fallback and require_confirmation:
            logger.info(f"â³ Asking user before proceeding: {plan.fallback}")
            results["asked_user"] = True
            results["user_message"] = plan.fallback
            return results
        
        # Execute each action
        for i, action in enumerate(plan.actions):
            tool_name = action.get('tool')
            params = action.get('params', {})
            
            logger.info(f"ðŸ”§ Executing action {i+1}/{len(plan.actions)}: {tool_name}")
            
            try:
                from ..tools.tool_executor import ToolCall
                tool_call = ToolCall(
                    tool=tool_name,
                    params=params,
                    reasoning=action.get('reasoning', '')
                )
                
                result = self.tools.execute_tool(tool_call)
                
                if result.get('success'):
                    results["executed"].append({
                        "tool": tool_name,
                        "params": params,
                        "result": result
                    })
                    logger.info(f"âœ… Action {tool_name} succeeded")
                else:
                    results["failed"].append({
                        "tool": tool_name,
                        "error": result.get('error', 'Unknown error')
                    })
                    logger.warning(f"âŒ Action {tool_name} failed: {result.get('error')}")
                    
                    # Stop on critical failure
                    break
                    
            except Exception as e:
                logger.error(f"Error executing {tool_name}: {e}")
                results["failed"].append({
                    "tool": tool_name,
                    "error": str(e)
                })
                break
        
        # Store in memory
        self.memory.store(
            content=f"Executed plan: {plan.goal}. Success: {len(results['executed'])}, Failed: {len(results['failed'])}",
            importance=0.8,
            metadata={
                "type": "action_plan",
                "goal": plan.goal,
                "results": results
            }
        )
        
        return results
    
    async def handle_user_request(self, user_text: str) -> Dict:
        """
        Handle a direct user request
        Example: "Send Papa the document he asked for"
        """
        logger.info(f"ðŸŽ¯ Handling user request: {user_text}")
        
        # Build prompt for user request
        context = self.memory.get_context_for_llm(max_items=5)
        tools_desc = self.tools.registry.get_tool_descriptions()
        
        prompt = f"""You are AURA, an intelligent assistant. The user has made a request.

USER REQUEST: "{user_text}"

CONTEXT: {context}

{tools_desc}

Analyze this request and create a plan to accomplish it. Consider:
1. What does the user want to achieve?
2. What information do you need?
3. What steps are required?
4. Are there any security/privacy concerns?

Respond in JSON format:
```json
{{
  "understood_goal": "What you think the user wants",
  "information_needed": ["list", "of", "missing", "info"],
  "plan": [
    {{"step": 1, "action": "tool_name", "params": {{}}, "reasoning": "why"}}
  ],
  "can_proceed": true/false,
  "clarification_needed": "question to ask user if you need more info"
}}
```

Your response:"""
        
        # Get LLM response
        response = self.llm.generate(prompt=prompt, max_tokens=1024)
        
        # Parse and execute
        try:
            json_match = __import__('re').search(r'```(?:json)?\s*({[\s\S]*?})\s*```', response)
            if json_match:
                data = json.loads(json_match.group(1))
                
                if not data.get('can_proceed'):
                    return {
                        "success": False,
                        "needs_clarification": True,
                        "message": data.get('clarification_needed', 'I need more information to help with that.')
                    }
                
                # Convert to action plan
                plan = ActionPlan(
                    goal=data.get('understood_goal', user_text),
                    reasoning="User request",
                    actions=data.get('plan', []),
                    fallback=None
                )
                
                # Execute
                return await self.execute_plan(plan, require_confirmation=True)
                
        except Exception as e:
            logger.error(f"Error handling request: {e}")
        
        return {
            "success": False,
            "message": "I'm not sure how to help with that yet. Can you provide more details?"
        }
